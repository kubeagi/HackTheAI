# GPU

## 常见的英伟达 GPU 规格与参考售价

英伟达显卡“相对版本号”官方对照表，数字越大代表支持功能越多：
[CUDA GPUs - Compute Capability | NVIDIA Developer](https://developer.nvidia.com/cuda-gpus)

浮点性能参考：

https://blog.csdn.net/weixin_45941288/article/details/131089570

[NVIDIA Tesla GPU系列P40参数性能——不支持半精度(FP16)模型训练_凝眸伏笔的博客-CSDN博客](https://blog.csdn.net/pearl8899/article/details/112875396)

[NVIDIA Tesla GPU系列P4、T4、P40以及V100参数性能对比-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/753454)

### 消费级/专业显卡（面向个人及小型工作站）

| 名称     | 核心代号^1^ | 流处理器数量^2^ | 显存类型^3^ | 显存容量 | 显存位宽^4^ | 显存带宽^5^ | FP16 性能^6^ | 参考售价^7^ |
| -------- | ----------- | --------------- | ----------- | -------- | ----------- | ----------- | ------------ | ----------- |
| 3060     | GA106       | 3584            | GDDR6       | 12 GB    | 192-bit     | 360 GB/s    | 24 TFlops    | ￥2,000     |
| 2080 Ti  | TU102       | 4352            | GDDR6       | 11 GB    | 352-bit     | 616 GB/s    | 53.8 TFlops  | ￥1,800     |
| 3080     | GA102       | 8960            | GDDR6X      | 10 GB    | 320-bit     | 760 GB/s    | 59.5 TFlops  | ￥3,000     |
| 3080 Ti  | GA102       | 10240           | GDDR6X      | 12 GB    | 320-bit     | 760 GB/s    | 70 TFlops    | ￥4,000     |
| 3090     | GA102       | 10496           | GDDR6X      | 24 GB    | 384-bit     | 960 GB/s    | 71 TFlops    | ￥5,700     |
| 4080     | AD103       | 9728            | GDDR6X      | 16 GB    | 256-bit     | 736 GB/s    | 98 TFlops    | ￥8,500     |
| 4090     | AD102       | 16384           | GDDR6X      | 24 GB    | 384-bit     | 960 GB/s    | 165.2 TFlops | ￥12,000    |
| A2000    | GA106       | 3328            | GDDR6       | 12 GB    | 192-bit     | 288 GB/s    | 32 TFlops    | ￥3,000     |
| A4000    | GA104       | 6144            | GDDR6       | 16 GB    | 256-bit     | 448 GB/s    | 76.7 TFlops  | ￥5,700     |
| A4500    | GA102       | 7168            | GDDR6       | 20 GB    | 320-bit     | 640 GB/s    | 94.6 TFlops  | ￥9,600     |
| A5000    | GA102       | 8192            | GDDR6       | 24 GB    | 384-bit     | 768 GB/s    | 117 TFlops   | ￥11,000    |
| A5500    | GA102       | 10240           | GDDR6       | 24 GB    | 384-bit     | 768 GB/s    | 136.4 TFlops | ￥25,000    |
| A6000    | GA102       | 10752           | GDDR6       | 48 GB    | 384-bit     | 768 GB/s    | 155 TFlops   | ￥29,000    |
| 6000 Ada | AD102       | 18176           | GDDR6X      | 48 GB    | 384-bit     | 960 GB/s    | 210.6 TFlops | /           |

### 计算卡（面向数据中心）

| 名称 | 核心代号 | 显存类型 | 显存容量 | 显存带宽   | FP16 性能     | 参考售价 |
| ---- | -------- | -------- | -------- | ---------- | ------------- | -------- |
| T4   | TU104    | GDDR6    | 16 GB    | 300 GB/s   | 16 TFlops     | ￥5,600  |
| P40  | GP102    | GDDR5X   | 24 GB    | 192 GB/s   | 11.76 TFlops  | ￥1,200  |
| P100 | GP100    | HBM2     | 16 GB    | 732 GB/s   | 18.7 TFlops   | ￥1,350  |
| V100 | GV100    | HBM2     | 32 GB    | 870 GB/s   | 118.5 TFlops  | ￥14,000 |
| A2   | GA107    | GDDR6    | 16 GB    | 200 GB/s   | 18 TFlops     | ￥8,400  |
| A10  | GA102    | GDDR6    | 24 GB    | 600 GB/s   | 125 TFlops    | ￥10,000 |
| A30  | GA100    | HBM2     | 24 GB    | 933 GB/s   | 165 TFlops    | ￥24,000 |
| A40  | GA100    | GDDR6    | 48 GB    | 696 GB/s   | 149.7 TFlops  | ￥25,000 |
| A800 | GA100    | HBM2e    | 80 GB    | 1,935 GB/s | 312 TFlops    | ￥85,000 |
| L4   | AD102    | GDDR6    | 24 GB    | 300 GB/s   | 242 TFlops    | /        |
| L40  | AD102    | GDDR6    | 48 GB    | 864 GB/s   | 181.05 TFlops | /        |
| H800 | GH100    | HBM2e    | 80 GB    | 2 TB/s     | 1513 TFlops   | /        |

### 备注

-   1：核心代号：GPU 核心的编号。同一个核心可以通过“屏蔽”计算单元（出于节约成本的目的，被戏称为“刀法”）、拓展不同的外围配置等方式，生产不同性能、不同产品线的 GPU。
    -   前两位字母 = 核心架构代号。
        -   GP = Pascal 架构 = GTX 10 系列
        -   GV = Volta 架构 = 20 系计算卡特化
        -   TU = Turing 架构 = RTX 20 系列
        -   GA = Ampere 架构 = RTX 30 系列
        -   AD = Ada Lovelace 架构 = RTX 40 系列
        -   GH = Hopper 架构 = 40 系计算卡特化
    -   后三位数字 = 核心尺寸分类。最后一位数字越大 = 核心尺寸越小。
-   2：流处理器数量：衡量 GPU 规模的参数，英伟达称为【CUDA 单元数】。
    -   流处理器 = 着色器 = GPU 计算的基本单元。
    -   流处理器数量不严格与算力呈正比。计算卡根据定位不同，通常屏蔽了核心内的特定模块，故计算卡不展示流处理器数量
    -   由于架构换代更新时对流处理器有修改，不同架构之间的流处理器数量不可直接进行比对。
-   3：显存类型：
    -   GDDR：常见的显存类型，原理与 DDR 内存相似。GDDR6 > GDDR5；有 X 后缀的（X = 超频） > 没有 X 后缀的。
    -   HBM：通过堆叠颗粒实现超高位宽与带宽，代价是造价昂贵。
    -   GDDR 与 HBM 的位宽没有可比性，因此计算卡列表不展示位宽。
-   4：显存位宽：GPU 核心与显存交换数据的【车道宽度】。
-   5：显存带宽：GPU 核心与显存交换数据的【车流量上限】。
-   6：FP16 性能：也即半精度浮点计算能力。在不进行“量化”等压缩处理方式的情况下，大多数模型均运行在 FP16 上。
    -   “量化” = 通过数学处理，以 INT8 或 INT4 格式处理矩阵计算，通常会利用 N 卡提供的 Tensor Core 或 RT Core，加速运算、降低模型的显存占用。
-   7：参考售价：截至 2023.7，数据来源为电商平台。

## AI 模型推理能力与显卡参数的定性关系

一般来说，一张显卡的算力，与显卡的以下参数呈正比（按影响程度排序）：

-   **架构**（新架构支持更多特性）
-   **FP16 浮点算力 **（也可参考 INT8、INT4 算力）
-   流处理器数量（计算卡由于核心特性不考虑）
-   显存带宽

此外，显存容量对能否盛放更大规模的模型起到至关重要的作用。70亿参数量级的模型不作“量化”处理需要13GB显存；参数量越大，需要占用的显存容量越大。“量化”等手段可以显著降低显存占用需求，例如70亿级模型在 INT4 模式下显存占用仅需 3GB，缺陷是其表现相比 FP16 状态会有少许下降，且目前需要配合 NVidia CUDA 使用。（AMD 的竞品 ROCm 及开源的 OpenCL 目前很不成熟）

## GPU 与 CPU 对比

-   AI 算法高并发的特性，决定了为并行计算诞生的 GPU 相对于为应付复杂指令设计的 CPU 通常有数倍至数十倍的效率优势。这一点不仅在 LLM 领域，而且在绝大多数涉及到深度学习的领域都是如此。
    -   以 ChatRWKV 为例，在4核8线程的 i7-1135G7 上，使用 1.5B 规模模型，占用 6GB 内存计算，生成答案的速度仅为 1 秒 3 ~ 4 字；通常演示中，显卡使用 7B 模型，占用大致相当的显存，生成答案的速度大约可达到 1 秒 20 ~ 30 字。
    -   一般模型如使用 Pytorch 等深度学习框架，CPU 推理效率与 GPU 的效率将会更加夸张。例如深度学习实践中常有【迭代次数/步数】的概念；现代消费级 CPU 通常需要数十秒至数分钟计算 1 步；一张中高端消费级显卡则通常仅需 1~2 秒；
-   显存带宽远大于内存带宽，适于高频读写模型数据。（DDR5 内存吞吐带宽通常为 90 ~ 100 GB/s 量级，远远不如显存）
-   许多针对模型计算的优化需要用到 INT8、INT4 计算能力，CPU 的复杂指令集并非均为这些计算设计，因此利用效率不高。
    -   如上述 RWKV 模型的 CPU 推理过程中，报告的 CPU 利用率仅仅只有 40%。

## NVLink ： 多 GPU 与算力虚拟化

由于 PCIe 等连接方式的带宽限制，一般情况下单一一张显卡无法直接访问其他显卡的显存，即无法直接将多个 GPU 之间的显存互联互通，大模型通常需要做复杂的拆分工作。

解决这一问题的技术在英伟达 GPU 中称为 NVLink。其通常可以提供 200 GB/s 以上的高速互联互通带宽，并使得模型和计算任务能够均匀地在两张或更多张显卡上同时运行。

由于市场的变化，自 RTX 20 系列以来，英伟达不断将 NVLink 技术上收：20 系时代，2070ti、2080、2080ti 均可使用桥接器；30 系时代，桥接接口被限制到只在 3090 上开放；而 40 系时代，桥接功能完全与消费级显卡绝缘，仅有专业计算卡可用。
